---
title: 游戏开发基础 图形学基础
author: Mingxian Yang
date: 2023-10-21 14:45:00 +0800
description: 有时候开发会遇到很多小小不言的问题，这些问题可能非常简单，但是我还是希望能记录下来。成长就是聚沙成塔的过程
categories: [Unity,游戏设计]
tags: [Unity]
render_with_liquid: false
---

图形学知识是基础，即便你在使用的游戏引擎已经帮你完成了大多数工作，但是这些基础的概念有助于你对渲染的过程有更好的理解，才会知其所以然。所以趁着复习的机会在这里整理一些必要的知识基础。

### 图形管线  
#### 图形管线概述
图形管线，这是绝大多数计算机渲染的基础过程。
渲染管线其实并不是一个很高深的名词，也有的人会叫做图形学管线、GPU渲染管线等，只是表示计算机如何把图形图像信息显示到你的屏幕上来这一过程，因为类似于工厂的流水线，所以才叫管线。  
图形管线要把模型转换成屏幕画面的过程，由于这个过程中所进行的操作严重依赖用户所使用的软件、硬件等，因此并不存在通用的绘图流水线。尽管如此，现今存在着类似Vulkan、OpenGL和DirectX的图形接口，将相似的操作统一起来，并把底层硬件抽象化，以减轻程序员的负担，逐渐成为最为主流的图形接口。  

泛化的来讲，图形管线在概念上一般分为3大阶段：
![GP](/assets/imgs/2023/GP.png)
1. **应用阶段(Application)**: 主要在CPU中进行，将所有图元（通常是三角形、线和点）传递到GPU的渲染管线，除此之外还有一些空间细分、碰撞检测、动画、变形都在此阶段进行，这些有助于减少内存使用。
2. **几何阶段(Geometry)**: 主要负责对输入的几何数据进行处理和转换。包括顶点着色器（Vertex Shader），它对输入的顶点进行变换和处理，例如执行模型变换、视图变换和投影变换等；还包括曲面细分（Tessellation）和几何着色器（Geometry Shader）等。
3. **光栅化阶段(Rasterization)**: 在这个阶段，几何数据被转换为屏幕上的像素片段。它将几何图形（如三角形）转换为像素片段，并确定每个像素片段的位置、颜色和其他属性
   
有很多文章中会分为4个阶段，除了上述的三个阶段外还会有： 

4. **像素处理阶段(Pixel)**: 该阶段对最终的像素进行处理和操作。包括混合（将多个像素的颜色进行混合）、深度测试（根据像素的深度值进行可见性判断）以及模板测试（根据像素的模板值进行特定操作）等

这是因为以前的老显卡仍然比较接近上述的图形管线。随着对GPU的需求不断增加，限制逐渐被消除，以创造更多的灵活性。现代显卡使用可自由编程、着色器控制的管道，允许直接访问各个处理步骤。为了减轻主处理器的负担，额外的处理步骤已移至管线和GPU。

*不过一般面试的时候你说只有三个阶段的话，面试官可能会觉得你一知半解，恰恰是第四阶段的深度测试、模板测试之类的会是高频考点 XD*

下面详细展开说一下各阶段的主要内容
#### 各阶段主要内容
 
1. **应用阶段：**  
   在CPU上执行，顾名思义，主要是将软件层面控制的一些工作的内容应用到需要渲染的图元。更通俗的来说就是在GPU绘制之前，告诉它你要画什么。主要内容是：视锥剔除以找到可能需要绘制的图元，生成渲染数据，设置渲染状态，绑定着色器参数，最后CallDraw呼叫GPU进行下一阶段。  
   
    *顺带一提，DrawCall是不是很熟悉(Unity优化时常见的术语), 为什么减少DrawCall可以提高游戏性能，原因就是：CPU频繁的调用GPU的绘画，每次都只提交很少的绘画内容，虽然CPU的计算很快，但是CPU频繁的DrawCall使得CPU的效率低下。
对于GPU而言, GPU的绘画速度远远快于CPU提交的速度，CPU成为了GPU的负担，而使用一些合批手段，尽量让CPU减少提交的次数，提高每次提高的内容，尽量减小CPU进行提交遇到的瓶颈*。这不就是融会贯通了吗。

2. **几何合阶段：** 
   几何阶段在GPU上运行，它处理应用阶段发送的渲染图元，负责大部分的逐三角性和逐顶点操作。几何阶段的一个重要任务就是把顶点坐标变换到屏幕空间中 ，再交给光栅器进行处理。主要有以下几个阶段：顶点着色、投影、裁剪、屏幕映射：
   1. 顶点着色：
        计算顶点位置，顶点从模型空间通过MVP转换到了齐次裁剪空间。*MVP变换不展开说了(其实是我也懒得看了)，不同图形接口的MVP不太一样。*  

        这里还会发生一件很重要的可选项：顶点着色，Unity Shader里面的Vertex Shader就是在这里处理的。这个阶段是完全可控制的，取决于你的Shader是怎么写的。（比如写一个草丛的Shader，顶点位置会周期性的摆动等）
  *此外，在顶点处理阶段的末尾，还有一些可选的阶段，包括曲面细分(tessellation)、几何着色(geometry shading)和流输出(stream output)，此处不详细描述*
  
    2. 裁剪阶段：
    对部分不在视体内部的图元进行裁剪。这部分是几乎完全由硬件控制的，因此没必要详细描述。
   这里的裁剪不同于剔除，剔除是决定图元需不需要渲染，而NDC裁剪在这里是将图元裁剪，这会减少部分像素处理的工作，如下图所示(值得注意的是，真实的渲染管线要复杂得多，这里只是说个大概意思)：
    <div alt="ndc" align=center><img src="/assets/imgs/2023/ndc.png"></div>
    <!-- ![ndc](/assets/imgs/2023/ndc.png) -->
    3. 屏幕映射：主要将之前步骤得到的坐标映射到屏幕坐标系。

1. **光栅化阶段：**
   光栅化阶段的目标是找到处于图元(三角形)内部的所有像素，进而将2D坐标顶点转为屏幕上的像素，每个像素附带深度和其他着色信息，它们一并传入pixel。
   光栅化阶段分为两个完全由硬件控制的子阶段：  
   1. 三角形设置(Triangle Setup)(图元装配): 计算出三角形的一些基本数据(如三条边的方程、深度值等)以供三角形遍历阶段使用。
   2. 三角形遍历(Triangle Traversal): 找到哪些像素被三角形所覆盖，并对这些像素的属性值进行插值。通过判断像素的中心采样点是否被三角形覆盖来决定该像素是否要生成片段。通过三角形三个顶点的属性数据，插值得到每个像素的属性值。此外透视校正插值也在这个阶段执行。
   
2. **像素处理阶段：** 
   它主要处理光栅化阶段发送过来的在图元内部的片元序列。GPU会对每个片元进行像素操作，如颜色和深度的计算、纹理采样、混合等。主要分为两大阶段：
   1. 像素着色：使用光栅化阶段传递的插值后的数据以及纹理计算像素颜色，进行光照计算和阴影处理，决定屏幕像素的最终颜色
   *需要注意的是，纹理可以认为是一种独立于”插值“数据的一种资源。由于顶点和像素着色器一般数据都存在更小更快的L1缓存(L1 Cache)中，但纹理存储在更大更慢的L2缓存(L2 Cache)中，因此纹理访问是有延迟的，线程先执行不产生延迟的指令，当遇到产生延迟的指令时，快速切换到其他片元执行其他任务并递归运行。Shader占用的寄存器越多，当内存延迟时，有可能会产生线程被迫等待的情况，这被称作占用率过高*
   2. 测试合并：包括各种测试和混合操作，如裁剪测试、透明测试、模板测试、深度测试以及色彩混合等。经过了测试合并阶段，并存到帧缓冲的像素值，才是最终呈现在屏幕上的图像。  
    *深度测试是在像素着色器之后才执行的。这种做法会导致很多不可见的像素也会执行像素着色器计算，从而浪费了计算资源。为了避免这种浪费，后来的GPU架构采用了Early-Z技术，将深度测试提前到像素着色器之前(如下图所示)。这样一来，Early-Z技术就可以在像素着色器之前剔除很多无效的像素，从而避免它们进入像素着色器，提高了渲染性能*
    *我们的屏幕显示的就是颜色缓冲区中的颜色值。但是， 为了避免我们看到那些正在进行光栅化的图元，GPU会使用双重缓冲(Double Buffering) 的策略，GPU会交换后置缓冲区和前置缓冲区的内容确保用户只会看到已经渲染好的内容*

### **Ref**   
<!-- http://www.gamelook.com.cn/2016/10/268460 -->
https://en.wikipedia.org/wiki/Graphics_pipeline
https://zhuanlan.zhihu.com/p/430541328
https://zhuanlan.zhihu.com/p/627201581

 [**作者博客：YMX's Site**](http://yangmingxian.com/)  
 [**作者B站视频：CyberStreamer**](https://space.bilibili.com/22212765)




