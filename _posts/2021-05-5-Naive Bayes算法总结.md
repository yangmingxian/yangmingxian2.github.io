---
title: Naive Bayes算法总结
author: Mingxian Yang
date: 2023-08-19 18:10:00 +0800
description: 在众多的分类模型中，应用最为广泛的两种分类模型是决策树模型(Decision Tree Model)和朴素贝叶斯模型（Naive Bayesian Model，NBC）。朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，NBC模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为NBC模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，这给NBC模型的正确分类带来了一定影响。在属性个数比较多或者属性之间相关性较大时，NBC模型的分类效率比不上决策树模型。而在属性相关性较小时，NBC模型的性能最为良好。
categories: [机器学习,算法]
tags: [机器学习]
render_with_liquid: true
math: true
---

### 思想
对于给定的待分类项x，通过学习到的模型计算后验概率分布，即：在此项出现的条件下各个目标类别出现的概率，将后验概率最大的类作为x所属的类别。后验概率根据贝叶斯定理计算。 朴素贝叶斯属于**生成模型**。 

**关键**：为避免贝叶斯定理求解时面临的组合爆炸、样本稀疏问题，引入了条件独立性假设。用于分类的特征在类确定的条件下都是条件独立的。

### 朴素贝叶斯“朴素”在哪里
简单来说：利用贝叶斯定理求解联合概率$P(XY)$时，需要计算条件概率$P(X\mid Y)$。  
在计算$P(X\mid Y)$时，朴素贝叶斯做了一个很强的条件独立假设（当$Y$确定时，$X$的各个分量取值之间相互独立），即  

$$
\begin{array}{c}
P\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots X_{j}=x_{j} \mid Y=y_{k}\right) \\
=P\left(X_{1}=x_{1} \mid Y=y_{k}\right) * P\left(X_{2}=x_{2} \mid Y=y_{k}\right) * \ldots * P\left(X_{j}=x_{j} \mid Y=y_{k}\right)
\end{array}
$$

### 朴素贝叶斯优缺点
优点：对小规模的数据表现很好，适合多分类任务，适合增量式训练。  
缺点：对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）。  